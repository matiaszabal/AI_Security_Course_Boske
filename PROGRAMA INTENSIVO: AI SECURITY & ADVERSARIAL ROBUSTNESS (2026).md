## PROGRAMA INTENSIVO: AI SECURITY & ADVERSARIAL ROBUSTNESS (2026)

### MES 1: FUNDAMENTOS Y SEGURIDAD EN MODELOS DE VISIÓN

### SEMANA 1: TAXONOMÍA DE AMENAZAS Y MODELADO DE RIESGOS

- **Sesión 1:** Introducción a la Seguridad de IA. Diferenciación técnica entre AI Security, Safety y Ethics. Implementación del marco MITRE ATLAS en la estrategia corporativa.
- **Sesión 2:** Análisis de superficies de ataque. Identificación de vectores en las fases de entrenamiento, inferencia y despliegue. Modelado de amenazas para entornos locales y arquitecturas cloud.
- **Sesión 3:** Vulnerabilidades en infraestructura de ML. Auditoría de seguridad en librerías críticas: PyTorch, TensorFlow y Scikit-Learn.

### SEMANA 2: ATAQUES DE EVASIÓN (ADVERSARIAL EXAMPLES)

- **Sesión 4:** Fundamentos matemáticos de la perturbación. Análisis de gradientes, funciones de pérdida y manipulación de tensores.
- **Sesión 5:** Ataques de Caja Blanca. Ejecución técnica de FGSM (Fast Gradient Sign Method) y PGD (Projected Gradient Descent).
- **Sesión 6:** Ataques de Caja Negra y Transferibilidad. Metodologías de ataque sin acceso a los pesos del modelo mediante el uso de modelos sustitutos.

### SEMANA 3: ENVENENAMIENTO DE DATOS Y ROBUSTEZ (LABORATORIO 1)

- **Sesión 7:** Ataques de Envenenamiento (Data Poisoning). Técnicas de inserción de backdoors en datasets y manipulación de etiquetas de entrenamiento.
- **Sesión 8:** Estrategias de Defensa I. Entrenamiento Adversarial, destilación defensiva y técnicas de pre-procesamiento de señales para mitigación de ruido.
- **Sesión 9:** **EJECUCIÓN LABORATORIO 1:** Implementación y defensa de ataques FGSM sobre datasets de visión por computadora.

### SEMANA 4: SEGURIDAD EN MODELOS DE LENGUAJE (LLMS)

- **Sesión 10:** Arquitectura de Transformers y vectores de ataque específicos. Aplicación del OWASP Top 10 for LLM Applications.
- **Sesión 11:** Inyección de Prompts I. Inyección directa y técnicas de ingeniería social aplicadas a la lógica de modelos de lenguaje.
- **Sesión 12:** Inyección de Prompts II. Inyección indirecta mediante fuentes externas (buscadores, correos electrónicos y documentos dinámicos).

---

### MES 2: LLM SECURITY, RAG Y SECMLOPS

### SEMANA 5: JAILBREAKING Y ATAQUES SEMÁNTICOS AVANZADOS

- **Sesión 13:** Metodologías de Jailbreaking. Evasión de alineación (RLHF) mediante roleplay, técnicas de codificación y ataques multimodales.
- **Sesión 14:** Exfiltración de datos y ataques de canal lateral (Side-channel) durante la inferencia de modelos generativos.
- **Sesión 15:** Privacidad y Extracción de Información. Ataques de Inversión de Modelos e Inferencia de Pertenencia (Membership Inference).

### SEMANA 6: SEGURIDAD EN ARQUITECTURAS RAG Y AGENTES (LABORATORIO 2)

- **Sesión 16:** Vulnerabilidades en Sistemas RAG. Envenenamiento de bases vectoriales y manipulación de los mecanismos de recuperación de información.
- **Sesión 17:** Riesgos en Agentes Autónomos. Análisis de escalada de privilegios y ejecución no autorizada de herramientas externas (Tool Use).
- **Sesión 18:** **EJECUCIÓN LABORATORIO 2:** Exfiltración de secretos corporativos en entornos RAG mediante técnicas de inyección indirecta.

### SEMANA 7: SECMLOPS Y SEGURIDAD EN LA CADENA DE SUMINISTRO (LABORATORIO 3)

- **Sesión 19:** Serialización insegura y ejecución remota de código (RCE). Riesgos críticos en formatos Pickle y binarios de PyTorch.
- **Sesión 20:** Hardening de Pipelines de ML. Implementación de escaneo de modelos, firmas digitales y migración hacia formatos seguros (SafeTensors).
- **Sesión 21:** **EJECUCIÓN LABORATORIO 3:** Detección de backdoors semánticos y aseguramiento del entorno de ejecución mediante Docker Sandboxing.

### SEMANA 8: RED TEAMING DE IA Y CERTIFICACIÓN FINAL

- **Sesión 22:** Metodología de Red Teaming en entornos industriales. Automatización de pruebas de estrés con frameworks especializados (PyRIT, Garak).
- **Sesión 23:** Gobernanza y respuesta ante incidentes. Implementación de Guardrails programáticos (NVIDIA NeMo, Llama Guard) y monitoreo de drift adversarial.
- **Sesión 24:** **EXAMEN FINAL DE CERTIFICACIÓN:** Auditoría técnica integral de un sistema inteligente bajo condiciones de adversario real.

---

### ESTRUCTURA DE CARGA HORARIA

- **Sesiones Sincrónicas:** 3 encuentros semanales de 3 horas cada uno (Martes, Jueves y Sábados).
- **Trabajo Independiente:** 2 horas diarias dedicadas a investigación y ejecución de laboratorios.
- **Total del Programa:** 160 horas cátedra.
